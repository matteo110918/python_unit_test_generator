{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import os"
   ],
   "id": "49f90a16c6793525",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
   ],
   "id": "40c8359b3fc4bfa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "openai = OpenAI()\n",
    "OPENAI_MODEL = \"gpt-4o-mini\""
   ],
   "id": "49f7c8548a86dde6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a highly skilled assistant specialized in generating Python unit tests. Your task is to create valid and well-structured unit tests for a given Python function. Output only the test class and test methods directly, with no introduction, explanation, or summary text.\n",
    "If no Python function is provided in the input, respond with the following message: 'Please provide a Python function so that I can generate unit tests for it.'\n",
    "\n",
    "When generating tests:\n",
    "- Use the unittest framework.\n",
    "- Ensure the test class and methods are formatted as valid Python code.\n",
    "- Include specific test cases for edge cases, typical use cases, and invalid inputs.\n",
    "- Ensure appropriate assertions for each test case.\n",
    "- Mock external dependencies if necessary.\n",
    "\n",
    "The output must strictly follow this format:\n",
    "\n",
    "'class Test[FunctionName](unittest.TestCase):\n",
    "    \n",
    "    def test_case_name(self):\n",
    "        # Comment describing the purpose of this test case\n",
    "        self.assertEqual(actual, expected)\n",
    "'\n",
    "\n",
    "Do not include any additional text, explanations, or summaries. Only provide the Python test code as a unittest class or request a function if none is given.\n",
    "\"\"\""
   ],
   "id": "23e15d8483b1ef36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def user_prompt_for(python):\n",
    "    user_prompt = \"Below is a Python function for which I need unit tests. Include edge cases, typical use cases, and invalid inputs.\"\n",
    "    user_prompt += \"Please analyze the function and generate comprehensive test cases using the `unittest` framework.\"\n",
    "    user_prompt += \"If necessary, use mocking for external dependencies.\\n\\n\"\n",
    "    user_prompt += python\n",
    "    return user_prompt"
   ],
   "id": "c9a1c5ac73893e3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def messages_for_python(python):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(python)}\n",
    "    ]"
   ],
   "id": "7785358c11779290",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def documentation_python(python):\n",
    "    stream = openai.chat.completions.create(model=OPENAI_MODEL, messages=messages_for_python(python), stream=True)\n",
    "    reply = \"\"\n",
    "    for chunk in stream:\n",
    "        fragment = chunk.choices[0].delta.content or \"\"\n",
    "        reply += fragment\n",
    "        yield reply.replace('```python\\n','').replace('import unittest\\n','').replace('```','')"
   ],
   "id": "2ec0a29f2e098792",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "simple_function_python = \"\"\"\n",
    "def calculate_area(length, width):\n",
    "    return length * width\n",
    "\"\"\""
   ],
   "id": "9fb1ca124f693afb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "documentation_python(simple_function_python)",
   "id": "d45dd6d4e512622f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with gr.Blocks() as ui:\n",
    "    gr.Markdown(\"# Python Unit Test Generator\")\n",
    "    gr.Markdown(\"Paste your Python function in the left panel, and click the button to 'Generate Unit Tests'.\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        code_input = gr.Code(label=\"Code snippets:\", lines=10, value=simple_function_python, language=\"python\")\n",
    "        code_doc = gr.Code(label=\"Unit tests:\", language=\"python\")\n",
    "    with gr.Row():\n",
    "        convert = gr.Button(\"Generate Unit Tests\")\n",
    "    \n",
    "    convert.click(documentation_python, inputs=[code_input], outputs=[code_doc])\n",
    "    \n",
    "ui.launch(inbrowser=True, share=True)"
   ],
   "id": "58c34ec74095f11c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
